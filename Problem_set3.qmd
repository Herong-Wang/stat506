---
title: "Problem set 3"
author: "Herong Wang"
format: 
  html:
    embed-resources: true
    code-fold: true
    code-summary: "Show the code"
editor: visual
---

# Github repo link: https://github.com/Herong-Wang/stat506

# Problem 1 - vision

## read in datasets

```{r}
library(dplyr)
library(haven)

## read in the VIX_D.XPT file stored in the Problem_set3 folder in my laptop into vix
vix <- read_xpt("C:/Users/herongw/Desktop/Umich_Phd/2024fall/STAT506/Problem_set3/VIX_D.XPT")

## read in DEMO_D.XPT file stored in the Problem_set3 folder in my laptop into demo
demo <- read_xpt("C:/Users/herongw/Desktop/Umich_Phd/2024fall/STAT506/Problem_set3/DEMO_D.XPT")
```

## a. Merge the two files to create a single data.frame, using the SEQN variable for merging. Keep only records which matched. Print out your total sample size, showing that it is now 6,980.

```{r}

## inner join vix and demo data into vix.demo by SEQN

vix.demo <- merge(vix, demo, by = "SEQN")

nrow(vix.demo)

print(paste("The merged sample size from VIX_D and DEMO_D is", nrow(vix.demo)))
```

## b. Without fitting any models, estimate the proportion of respondents within each 10-year age bracket (e.g. 0-9, 10-19, 20-29, etc) who wear glasses/contact lenses for distance vision. Produce a nice table with the results.

```{r}

# I will cut the continuous age in years variable (RIDAGEYR) into categories by 10 and create a factor named age.int for age categories
vix.demo <- vix.demo %>% 
  mutate(age.int = cut(RIDAGEYR, breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90), right = FALSE, 
                       labels = c("0-9","10-19","20-29","30-39","40-49","50-59","60-69","70-79","80-89")))

# The coding for glasses/contact lenses for distance vision (VIQ220) is in mess
# I will create a new variable (distant.v) from the VIQ220 variable with 0=not wearing glasses/contact and 1=wearing glasses/contact and NA=missing/don't know
# This will be easier to calculate the proportion and for logistic regression for 1.c
table(vix.demo$VIQ220, useNA = "always")

vix.demo <- vix.demo %>% 
  mutate(distant.v = case_when(VIQ220 == 1 ~ 1,
                               VIQ220 == 2 ~ 0,
                               TRUE ~ NA))

table(vix.demo$VIQ220, vix.demo$distant.v, useNA = "always") # new variable matches with original variable!

# This will calculate the proportion of glasses/contact lenses for distance vision within each 10-year age bracket and create a HTML table
vix.demo %>% 
  group_by(age.int) %>% 
  summarise(n = n(), sum = sum(distant.v, na.rm = TRUE), p = round(sum/n, 2)) %>% 
  knitr::kable(., "html",
               col.names = c("10-year age bracket", "N within each 10-year age bracket",
                             "N for wearing galsses/contact for distance vision", "Proportion"))
  
```

## c. Fit three logistic regression models predicting whether a respondent wears glasses/contact lenses for distance vision. Predictors: 1)age, 2) age, race, gender, 3) age, race, gender, Poverty Income ratio. Produce a table presenting the estimated odds ratios for the coefficients in each model, along with the sample size for the model, the pseudo-R\^2, and AIC values.

```{r}
# lm1 predicts wearing glass/contact for distance vision with age
lm1 <- glm(distant.v ~ RIDAGEYR, data = vix.demo, family = "binomial")
summary(lm1)

# create a data frame with ORs, sample size, R^2 and AIC for lm1
# note for the predictors in the second and third model but not in this model (race, gender, poverty income ratio), I will leave the column values blank

lm1.result <- data.frame(
  Model = "Model 1",
  Variable = "Age",
  "Odds Ratio" = unname(exp(coef(lm1))[2]),
  "Sample size" = length(lm1[["residuals"]]),
  "Pseudo-R^2" = 1-(lm1$deviance/lm1$null.deviance),
  AIC = lm1$aic
)

# lm2 predicts wearing glass/contact for distance vision with age, race, gender
# I will make gender and race/ethnicity variable factor 

vix.demo$race <- factor(vix.demo$RIDRETH1, levels = c(1, 2, 3, 4, 5), labels = c("Mexican", "Other Hispanic", "Non-Hispanic White", "Non-Hispanic Black", "Other race"))

vix.demo$gender <- factor(vix.demo$RIAGENDR, levels = c(1, 2), labels = c("Male", "Female"))

lm2 <- glm(distant.v ~ RIDAGEYR + race + gender, data = vix.demo, family = "binomial")
summary(lm2)

# create a data frame with ORs, sample size, R^2 and AIC for lm2
# note for the predictors in third model but not in this model (poverty income ratio), I will leave the column value blank

lm2.result <- data.frame(
  Model = c("Model 2"),
  Variable = c("Age", names(exp(coef(lm2)[3])), names(exp(coef(lm2)[4])), names(exp(coef(lm2)[5])), 
               names(exp(coef(lm2)[6])), names(exp(coef(lm2)[7]))),
  "Odds Ratio" = unname(exp(coef(lm2)[-1])),
  "Sample size" = length(lm2[["residuals"]]),
  "Pseudo-R^2" = 1-(lm2$deviance/lm2$null.deviance),
  AIC = lm2$aic
)

# lm3 predicts wearing glass/contact for distance vision with age, race, gender, Poverty Income ratio
lm3 <- glm(distant.v ~ RIDAGEYR + race + gender + INDFMPIR, data = vix.demo, family = "binomial")
summary(lm3)

# create a data frame with ORs, sample size, R^2 and AIC for lm3

lm3.result <- data.frame(
  Model = c("Model 3"),
  Variable = c("Age", names(exp(coef(lm3)[3])), names(exp(coef(lm3)[4])), names(exp(coef(lm3)[5])), 
               names(exp(coef(lm3)[6])), names(exp(coef(lm3)[7])), "Poverty Income ratio"),
  "Odds Ratio" = unname(exp(coef(lm3)[-1])),
  "Sample size" = length(lm3[["residuals"]]),
  "Pseudo-R^2" = 1-(lm3$deviance/lm3$null.deviance),
  AIC = lm3$aic
)

# combine the result data frame for all three models and create a table


lm.results <- knitr::kable(rbind(lm1.result, lm2.result, lm3.result), "html",
               col.names = c("Model", "Variable", "Odds Ratio", "Sample size", "Pseudo-R^2", "AIC"), digits = 2)
lm.results
```

## d. From the third model from the previous part, test whether the odds of men and women being wears of glasess/contact lenses for distance vision differs. Test whether the proportion of wearers of glasses/contact lenses for distance vision differs between men and women. Include the results of the each test and their interpretation.

```{r}
library(multcomp)

# First I will test whether the odds of wearing glasses/contact differ for gender
summary(glht(lm3, "genderFemale = 0"))
exp(summary(glht(lm3, "genderFemale = 0"))$test$coefficients)
print("The odds of wearing glasses/contact for distance vision differs between men and women significantly with p value < 0.05. The odds of wearing  glasses/contact for distance vision for female is 1.68 times higher (168% higher) compared to male")

# Next I will use chisq-square test whether the proportion of wearing glasses/contact differ for gender
prop.table(table(vix.demo$distant.v, vix.demo$gender), margin = 2)
chisq.test(vix.demo$distant.v, vix.demo$RIAGENDR)

print("The proporation of wearing glasses/contact for distance vision differs between men and women signficantly with higher proportion among women compared to men")
```

# Problem set 2 - Sakila

## Read in files and create a function for query

```{r}
library(DBI)
sakila <- dbConnect(RSQLite::SQLite(), "C:/Users/herongw/Desktop/Umich_Phd/2024fall/STAT506/Problem_set3/sakila_master.db")
dbListTables(sakila)

#' This is a functin that helps me use dbGetQuery() easily
#' @param query is the query input
gg <- function(query) {
  dbGetQuery(sakila, query)
}
```

## a. What year is the oldest movie from, and how many movies were released in that year? Answer this with a single SQL query.

```{r}
gg("SELECT COUNT(film_id) as total, release_year 
   FROM film 
   GROUP BY release_year
   ORDER BY release_year")

print("The oldest movie came from 2006 and there were 1000 movies released in 2006")
```

## b. What genre of movie is the least common in the data, and how many movies are of this genre?

```{r}
## extract data using SQL and use regular R operation

film.category <- gg("SELECT * FROM film_category")
category.meta <- gg("SELECT * FROM category")

sort(table(film.category$category_id)) ## It turns out the genre with category_id 12 is the least common
category.meta[category.meta$category_id == 12,] ## Category_12 is Music movie

print("The music movie (category_id 12) is the least common in the data. There were 51 movies of this genre")

## use a single SQL query

gg("SELECT COUNT(f.film_id) as total, c.name
   FROM film_category as f
        INNER JOIN category as c ON f.category_id = c.category_id
   GROUP BY f.category_id
   ORDER BY total
   LIMIT 1")

print("I get the same result as above that the music movie is the least common in the data with 51 movies of this genre.")

```

## c. Identify which country or countries have exactly 13 customers.

```{r}
## extract data using SQL and use regular R operation
customer <- gg("select * from customer")
address <- gg("select * from address")
city <- gg("select * from city")
country <- gg("select * from country")

city$country <- country$country[match(city$country_id, country$country_id)]

address$country <- city$country[match(address$city_id, city$city_id)]

customer$country <- address$country[match(customer$address_id, address$address_id)]

table(customer$country)[table(customer$country) == 13]

print("The countries with 13 customers are Argentina and Nigeria")

## use a single SQL query

gg("SELECT COUNT(customer.customer_id) as total, country
   FROM customer
        LEFT JOIN (
          SELECT *
          FROM address 
               LEFT JOIN (
                 SELECT *
                 FROM city
                   LEFT JOIN country ON city.country_id = country.country_id
               ) AS m ON address.city_id = m.city_id
        ) AS r ON customer.address_id = r.address_id
   GROUP BY country
   HAVING total ==13")

print("The countries with 13 customers are Argentina and Nigeria")
```

# Problem 3 - US Records

## Read in dataset

```{r}
us <- read.csv("C:/Users/herongw/Desktop/Umich_Phd/2024fall/STAT506/Problem_set3/us-500.csv")
```

## a. What proportion of email addresses are hosted at a domain with TLD “.com”?

```{r}

length(grep("\\.com", us$email)) / nrow(us)

print(paste0("There are " , (length(grep(".com", us$email)) / nrow(us))*100, "% email address are hosted at a domain with TLD '.com'"))

```

## b. What proportion of email addresses have at least one non alphanumeric character in them? (Excluding the required “\@” and “.” found in every email address.)

```{r}
# First I will extract and only keep the string before @ in each email address
char <- matrix(unlist(strsplit(us$email, split = "@")), ncol=2, byrow=T)[, 1]

length(grep("[^a-zA-Z0-9]", char)) / length(us$email)

print("There are 50.6% of email addresses having at least one non-alphanumeric charater.")
```

## c. What are the top 5 most common area codes amongst all phone numbers? (The area code is the first three digits of a standard 10-digit telephone number.)

```{r}
sort(table(substr(us$phone1, 1,3)), decreasing = TRUE)[1:5]

print("The top 5 most common area codes are 973, 212, 215, 410, and 201")
```

## d. Produce a histogram of the log of the apartment numbers for all addresses. (You may assume any number at the end of the an address is an apartment number.)

```{r}
# I will extract all the numbers at the end of the address
match <- regexpr("[0-9]+$", us$address)
apt <- as.numeric(regmatches(us$address, match))
hist(log(apt), xlab = "log of the apartment numbers", main = "Histogram of log of the apartment number")

```

## e. Benford’s law is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford’s law. Do you think the apartment numbers would pass as real data?

```{r}
## First I will plot the probability of leading digits that obeys the Benford's law
## P is the probaility distribution of leading digits obeying Benford's law 
p <- sapply(seq(1,9), function(x) log10(x+1)-log10(x))
plot(seq(1,9), p, type = "b", col = "red", xlab = "leading digits", ylab = "probability")

## Next I will plot the distribution of leading digits for apartment number and plot it againt's Benford's law
leading.digit <- as.numeric(substr(apt, 1, 1))

h <- hist(leading.digit,plot=FALSE)
h$density <- h$counts/sum(h$counts)
plot(h,freq=FALSE, ylab='probalility')

lines(seq(1,9), p, type = "b", col = "red", lwd = 3)

print("From the plot we can tell that the apartment number does not follow Benford's law because the probability of high leading digits like 8 and 9 is higher compared to the Benford's law. I don't think the apartment numbers would pass as real data.")
```
